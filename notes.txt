checkpoint library: langgraph-checkpoint-postgres https://docs.langchain.com/oss/python/langgraph/persistence#checkpointer-libraries


write_file node
ask approval
wait for response on a separate http endpoint
on that endpoint, resume execution


docker compose -f docker-compose.dev.yml up --build

psql "host=localhost port=5432 dbname=idea_maestro user=idea_maestro"




agent graph which is accessible from function like:

get_agent_graph()

every endpoint that needs to execute the graph just calls:


    with PostgresSaver.from_conn_string(DB_URL) as checkpointer:

        checkpointer.setup()
        graph = get_agent_graph(checkpointer)


we could even create a decorator for the checkpointer


user questions scenarios:
- if the user is replying to a specific agent's question, that agent is automatically triggered
- if the user @s an agent directly, that agent is automatically triggered
- if the user does not do any of the above, the maestro is triggered


agent process:

1. think (reason): decide what step to take next

2. gather: gather information (from the user) or from files (read files)

3. act: make edits to files, handoff to another agent
-> seek approval before editing files



each agent has:

- system prompt: a base set of instructions (personality, goals, ego)

the maestro will have a special system prompt, as it orchestrates the others,
however even the other agents will be able to talk to each other, but everything goes through the approval of the maestro


not supporting events yet in the db schema



==*
on persisting messages

knowns:
- langchain has specific abstractions for messages
- if a node returns a list of messages in a state return, these are considered "deltas" and are automatically appended to the state messages list
- messages need to be persisted to support UI rendering and users visiting previous chats
- db: postgres
- langgraph also uses postgres for its checkpointer feature (resuming interuptions), however this is separate from the concern of persisting messages

actions:
- created a chat_messages table which stores all messages
    (grain is currently one row per message per thread)
    (but in future it will be one row per message per thread per user, adding a user_id col)
- added a 'seq' column, which is monotonically increasing by thread_id
- need to persist message deltas at the end of every node
*==

==*

DDL

create table if not exists chat_messages (
  id bigserial primary key,
  thread_id text not null,
  seq bigint not null,                 -- monotonic per thread
  role text not null,                  -- system | user | assistant | tool
  type text,                           -- optional: HumanMessage/AIMessage/ToolMessage
  content jsonb not null,              -- store as JSON (string or rich blocks)
  name text,                           -- tool name (for tool messages), optional
  tool_call_id text,                   -- for ToolMessage linking, optional
  tool_calls jsonb,                    -- for AIMessage.tool_calls, optional
  metadata jsonb default '{}'::jsonb,   -- model, token usage, etc
  created_at timestamptz not null default now(),
  by_agent text not null
  unique (thread_id, seq)
);

create index if not exists chat_messages_thread_seq
  on chat_messages (thread_id, seq);

create index if not exists chat_messages_thread_created
  on chat_messages (thread_id, created_at);

create table if not exists chat_threads (
  thread_id text primary key,
  next_seq bigint not null default 1
);

*==

sub-agent prompt structure

agent-name (agent-specific)
short-description (agent-specific)
core-values (agent-specific)
agent-goals (agent-specific)
style-and-tone (agent-specific)

shared-documents (global)
tool-use (global)

*==

